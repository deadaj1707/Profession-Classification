{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63ddd689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c15daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "acad_df=pd.read_csv('Academics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2a1485f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where does your passion for science come from?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foreign</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for science come from</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when I was a kid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I lived in a small village in France and</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Text  Category\n",
       "0  Where does your passion for science come from?       NaN\n",
       "1                                         foreign       NaN\n",
       "2                           for science come from       NaN\n",
       "3                                when I was a kid       NaN\n",
       "4        I lived in a small village in France and       NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acad_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d37cbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "law_df=pd.read_csv('Lawyers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "312698a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 2000, David Boies appeared before the Supre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in Bush v Gore you had sort of the highest sta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politically related case that was a case in wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>States was on the line and as someone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who as I said earlier it would have been a Ame...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Category\n",
       "0  In 2000, David Boies appeared before the Supre...         0\n",
       "1  in Bush v Gore you had sort of the highest sta...         0\n",
       "2  politically related case that was a case in wh...         0\n",
       "3              States was on the line and as someone         0\n",
       "4  who as I said earlier it would have been a Ame...         0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "law_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6791d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_df=pd.read_csv('Medicine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ae398cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you should know assuming yeah welcome to Nobel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>laureates yeah I were asked to bring a thing a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I loved these true things yeah I I won't expla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gift from my colleagues last year I got this a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ago on me and they III didn't know</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Category\n",
       "0  you should know assuming yeah welcome to Nobel...         1\n",
       "1  laureates yeah I were asked to bring a thing a...         1\n",
       "2  I loved these true things yeah I I won't expla...         1\n",
       "3  gift from my colleagues last year I got this a...         1\n",
       "4                 ago on me and they III didn't know         1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bea7965",
   "metadata": {},
   "outputs": [],
   "source": [
    "cre_df=pd.read_csv('Creatives.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42183d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I know we made a good piece of Television like...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>because of the story it was because of the hea...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to make a movie for $670 million for it to be ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and a lot of us come from that that truth than...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>script with The Hollywood Reporter I am your h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Category\n",
       "0  I know we made a good piece of Television like...       NaN\n",
       "1  because of the story it was because of the hea...       NaN\n",
       "2  to make a movie for $670 million for it to be ...       NaN\n",
       "3  and a lot of us come from that that truth than...       NaN\n",
       "4  script with The Hollywood Reporter I am your h...       NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d04bbbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mba_df=pd.read_csv('Mba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2efb27d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jamie, welcome and thank you very much for com...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>friends, from other places.   This is the thir...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regret in choosing our competitor on the east ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my daughter went to Harvard Business School an...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>But we love Stanford.    I like to come out he...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Category\n",
       "0  Jamie, welcome and thank you very much for com...       NaN\n",
       "1  friends, from other places.   This is the thir...       NaN\n",
       "2  regret in choosing our competitor on the east ...       NaN\n",
       "3  my daughter went to Harvard Business School an...       NaN\n",
       "4  But we love Stanford.    I like to come out he...       NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "465f891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_df=pd.read_csv('Engineer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4631bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ladies and gentlemen I have a dream a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dream that we can end poverty something</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm sure that we all share but to do</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that we have to change the conversation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>about poverty today I'm going to take us</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Text  Category\n",
       "0     ladies and gentlemen I have a dream a       NaN\n",
       "1   dream that we can end poverty something       NaN\n",
       "2      I'm sure that we all share but to do       NaN\n",
       "3   that we have to change the conversation       NaN\n",
       "4  about poverty today I'm going to take us       NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85f9e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df=pd.read_csv('Accountant.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ac23074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, I'm Bill Ackman.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm the CEO of Pershing Square Capital Managem...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you'll be ready to go. How to Start and Grow a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So let's begin. We're going to go into busines...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We're going to start a company and we're going...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Category\n",
       "0                               Hi, I'm Bill Ackman.       NaN\n",
       "1  I'm the CEO of Pershing Square Capital Managem...       NaN\n",
       "2  you'll be ready to go. How to Start and Grow a...       NaN\n",
       "3  So let's begin. We're going to go into busines...       NaN\n",
       "4  We're going to start a company and we're going...       NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5891f514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb92580b",
   "metadata": {},
   "source": [
    "Cleaning Dataset\n",
    "\n",
    "Lawyer-0\n",
    "Medicine-1\n",
    "Academic-2\n",
    "Engineer-3\n",
    "Creative-4\n",
    "MBA-5\n",
    "Accountant-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84f79714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Aditya\n",
      "[nltk_data]     Jha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Aditya\n",
      "[nltk_data]     Jha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Aditya\n",
      "[nltk_data]     Jha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Load NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Tokenize text\n",
    "        tokens = word_tokenize(text.lower())\n",
    "\n",
    "        # Remove stopwords and punctuation\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [word for word in tokens if (word not in stop_words and word not in string.punctuation)]\n",
    "\n",
    "        # Lemmatize words\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "        # Join tokens back into a string\n",
    "        clean_text = ' '.join(tokens)\n",
    "\n",
    "        return clean_text\n",
    "    else:\n",
    "        return ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46ee2a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Text  Category\n",
      "0           passion science come         2\n",
      "1                        foreign         2\n",
      "2                   science come         2\n",
      "3                            kid         2\n",
      "4     lived small village france         2\n",
      "...                          ...       ...\n",
      "2920       serious sort way half         2\n",
      "2921     century uh 's something         2\n",
      "2922         different also hard         2\n",
      "2923                   'm new 's         2\n",
      "2924            challenge 's joy         2\n",
      "\n",
      "[2925 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Clean the 'Text' column\n",
    "acad_df['Text'] = acad_df['Text'].apply(clean_text)\n",
    "\n",
    "# Assign each 'Category' as 2\n",
    "acad_df['Category'] = 2\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(acad_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e78950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text  Category\n",
      "0     2000 david boy appeared supreme court case bus...         0\n",
      "1                        bush v gore sort highest stake         0\n",
      "2       politically related case case presidency united         0\n",
      "3                                    state line someone         0\n",
      "4     said earlier would american history teacher n'...         0\n",
      "...                                                 ...       ...\n",
      "1545                       sometime may understand hope         0\n",
      "1546                                least catch england         0\n",
      "1547                    perhaps surpasses understanding         0\n",
      "1548                               problem vital supply         0\n",
      "1549                                              state         0\n",
      "\n",
      "[1550 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Clean the 'Text' column\n",
    "law_df['Text'] = law_df['Text'].apply(clean_text)\n",
    "\n",
    "# Assign each 'Category' as 0\n",
    "law_df['Category'] = 0\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(law_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96f937fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text  Category\n",
      "0     know assuming yeah welcome nobel week stockhol...         1\n",
      "1     laureate yeah asked bring thing artifact nobel...         1\n",
      "2                  loved true thing yeah wo n't explain         1\n",
      "3        gift colleague last year got miniature 27 year         1\n",
      "4                                      ago iii n't know         1\n",
      "...                                                 ...       ...\n",
      "2086                               song society rightly         1\n",
      "2087                               seeking 'm see 'm 'm         1\n",
      "2088                          believe thing begin basic         1\n",
      "2089                      principle get knowledge right         1\n",
      "2090                                  many people build         1\n",
      "\n",
      "[2091 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Clean the 'Text' column\n",
    "med_df['Text'] = med_df['Text'].apply(clean_text)\n",
    "\n",
    "# Assign each 'Category' as 1\n",
    "med_df['Category'] = 1\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(med_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "701e7e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Text  Category\n",
      "0              lady gentleman dream         3\n",
      "1       dream end poverty something         3\n",
      "2                     'm sure share         3\n",
      "3               change conversation         3\n",
      "4     poverty today 'm going take u         3\n",
      "...                             ...       ...\n",
      "2164     degree needed someone hold         3\n",
      "2165            hand teach day hold         3\n",
      "2166              degree hand begin         3\n",
      "2167                teach keep mind         3\n",
      "2168                      god bless         3\n",
      "\n",
      "[2169 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Clean the 'Text' column\n",
    "eng_df['Text'] = eng_df['Text'].apply(clean_text)\n",
    "\n",
    "# Assign each 'Category' as 1\n",
    "eng_df['Category'] = 3\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(eng_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2fea4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text  Category\n",
      "0     know made good piece television like know know...         4\n",
      "1                       story heart commitment n't need         4\n",
      "2                 make movie 670 million good know fact         4\n",
      "3               lot u come truth thank hey welcome offs         4\n",
      "4     script hollywood reporter host ivan orgy georg...         4\n",
      "...                                                 ...       ...\n",
      "3105                            let 's create character         4\n",
      "3106                                     could inspired         4\n",
      "3107                                     also keep vein         4\n",
      "3108                      edgar allen poe 's story well         4\n",
      "3109                  think scott stanley 's superb job         4\n",
      "\n",
      "[3110 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Clean the 'Text' column\n",
    "cre_df['Text'] = cre_df['Text'].apply(clean_text)\n",
    "\n",
    "# Assign each 'Category' as 4\n",
    "cre_df['Category'] = 4\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(cre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8e4a558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text  Category\n",
      "0     jamie welcome thank much coming today pleasure...         5\n",
      "1     friend place third 've come talk u ask lucky p...         5\n",
      "2     regret choosing competitor east coast business...         5\n",
      "3     daughter went harvard business school two son-...         5\n",
      "4     love stanford like come time come realize n't ...         5\n",
      "...                                                 ...       ...\n",
      "2428                    looked next said warehouse kind         5\n",
      "2429  true jit factory stuff come delivered right po...         5\n",
      "2430  warehouse delivery made daily sometimes freque...         5\n",
      "2431              outgoing warehouse everything visible         5\n",
      "2432                           reason able lot 've done         5\n",
      "\n",
      "[2433 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Clean the 'Text' column\n",
    "mba_df['Text'] = mba_df['Text'].apply(clean_text)\n",
    "\n",
    "# Assign each 'Category' as 1\n",
    "mba_df['Category'] = 5\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(mba_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59f5f298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text  Category\n",
      "0                                     hi 'm bill ackman         6\n",
      "1     'm ceo pershing square capital management 'm t...         6\n",
      "2                      'll ready go start grow business         6\n",
      "3           let 's begin 're going go business together         6\n",
      "4     're going start company 're going start lemona...         6\n",
      "...                                                 ...       ...\n",
      "2007                            big idea well next time         6\n",
      "2008                               small idea next time         6\n",
      "2009                             want something go talk         6\n",
      "2010                    accountant get financial mentor         6\n",
      "2011                                              thank         6\n",
      "\n",
      "[2012 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Clean the 'Text' column\n",
    "acc_df['Text'] = acc_df['Text'].apply(clean_text)\n",
    "\n",
    "# Assign each 'Category' as 1\n",
    "acc_df['Category'] = 6\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(acc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35f39631",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([law_df, med_df, acad_df, eng_df, cre_df, mba_df, acc_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8fe82dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000 david boy appeared supreme court case bus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bush v gore sort highest stake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politically related case case presidency united</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>state line someone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>said earlier would american history teacher n'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>big idea well next time</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>small idea next time</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>want something go talk</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>accountant get financial mentor</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>thank</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16290 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Category\n",
       "0     2000 david boy appeared supreme court case bus...         0\n",
       "1                        bush v gore sort highest stake         0\n",
       "2       politically related case case presidency united         0\n",
       "3                                    state line someone         0\n",
       "4     said earlier would american history teacher n'...         0\n",
       "...                                                 ...       ...\n",
       "2007                            big idea well next time         6\n",
       "2008                               small idea next time         6\n",
       "2009                             want something go talk         6\n",
       "2010                    accountant get financial mentor         6\n",
       "2011                                              thank         6\n",
       "\n",
       "[16290 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "faa39871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the rows\n",
    "combined_df = combined_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81b76844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smoking ban maybe think administration stay</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>energy 's matter fostering open communication ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people pakistan every day answer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>liquid position many day get told ten</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fundamentally 's operating system 's better pl...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16285</th>\n",
       "      <td>n't need another hero tina 's dancing queen</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16286</th>\n",
       "      <td>solved started yet exactly</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16287</th>\n",
       "      <td>bad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16288</th>\n",
       "      <td>want tell kept low made sure equitable everyon...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16289</th>\n",
       "      <td>year period time multiple world war kind know ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16290 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Category\n",
       "0            smoking ban maybe think administration stay         5\n",
       "1      energy 's matter fostering open communication ...         2\n",
       "2                       people pakistan every day answer         3\n",
       "3                  liquid position many day get told ten         5\n",
       "4      fundamentally 's operating system 's better pl...         5\n",
       "...                                                  ...       ...\n",
       "16285        n't need another hero tina 's dancing queen         4\n",
       "16286                         solved started yet exactly         1\n",
       "16287                                                bad         1\n",
       "16288  want tell kept low made sure equitable everyon...         4\n",
       "16289  year period time multiple world war kind know ...         6\n",
       "\n",
       "[16290 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cf7afa",
   "metadata": {},
   "source": [
    "Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67ecc5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nTrainer requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFTrainer\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11184\\1476470514.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m# Define Trainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m trainer = Trainer(\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\utils\\dummy_pt_objects.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   9486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9487\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9488\u001b[1;33m         \u001b[0mrequires_backends\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"torch\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   9489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001b[0m in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1281\u001b[0m     \u001b[1;31m# Raise an error for users who might not realize that classes without \"TF\" are torch-only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1282\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m\"torch\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbackends\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"tf\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbackends\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1283\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPYTORCH_IMPORT_ERROR_WITH_TF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m     \u001b[1;31m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: \nTrainer requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFTrainer\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load combined_df\n",
    "# combined_df = pd.read_csv('combined_df.csv')  # Assuming you have combined_df saved as a CSV file\n",
    "\n",
    "# Split data into features and labels\n",
    "texts = combined_df['Text'].tolist()\n",
    "labels = combined_df['Category'].tolist()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize texts\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
    "\n",
    "# Convert labels to tensors\n",
    "train_labels = tf.convert_to_tensor(train_labels)\n",
    "test_labels = tf.convert_to_tensor(test_labels)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',   # Provide a directory to save the model and logs\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=1000,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "# Load DistilBERT model for sequence classification\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=7)\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=(train_encodings, train_labels),\n",
    "    eval_dataset=(test_encodings, test_labels)\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Use the trained model for inference\n",
    "def predict_category(text):\n",
    "    # Preprocess text\n",
    "    inputs = tokenizer(text, return_tensors='tf', truncation=True, padding=True)\n",
    "    \n",
    "    # Perform inference\n",
    "    outputs = model(inputs)\n",
    "    probabilities = tf.nn.softmax(outputs.logits, axis=1).numpy()[0]\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "# Example usage:\n",
    "new_text = \"I am passionate about coding and building software.\"\n",
    "probabilities = predict_category(new_text)\n",
    "category_labels = ['Lawyer', 'Medicine', 'Academic', 'Engineer', 'Creative', 'MBA', 'Accountant']\n",
    "for category, probability in zip(category_labels, probabilities):\n",
    "    print(f\"{category}: {probability * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "feec802a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.2.1-cp39-cp39-win_amd64.whl (198.5 MB)\n",
      "     ------------------------------------ 198.5/198.5 MB 529.8 kB/s eta 0:00:00\n",
      "Collecting typing-extensions>=4.8.0\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aditya jha\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\aditya jha\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\aditya jha\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\aditya jha\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\aditya jha\\anaconda3\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\aditya jha\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\aditya jha\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Installing collected packages: typing-extensions, torch\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "Successfully installed torch-2.2.1 typing-extensions-4.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24a56905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\Aditya Jha\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Aditya Jha\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "815/815 [==============================] - 1775s 2s/step - loss: 1.3015 - accuracy: 0.5153\n",
      "Epoch 2/3\n",
      "815/815 [==============================] - 2469s 3s/step - loss: 0.8514 - accuracy: 0.7010\n",
      "Epoch 3/3\n",
      "815/815 [==============================] - 5552s 4s/step - loss: 0.5241 - accuracy: 0.8201\n",
      "{0: 0.000270618, 1: 0.00013845049, 2: 0.0027205795, 3: 0.99279493, 4: 0.00014726695, 5: 0.0036457388, 6: 0.00028242145}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Define DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize input data\n",
    "def tokenize_data(text):\n",
    "    return tokenizer(text, padding=True, truncation=True, return_tensors='tf')\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    combined_df['Text'].tolist(), \n",
    "    combined_df['Category'].tolist(), \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Tokenize training and testing data\n",
    "train_encodings = tokenize_data(train_texts)\n",
    "test_encodings = tokenize_data(test_texts)\n",
    "\n",
    "# Define TensorFlow Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    "))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_labels\n",
    "))\n",
    "\n",
    "# Define DistilBERT model architecture for sequence classification\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=7)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = ['accuracy']\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset.shuffle(1000).batch(16), epochs=3, batch_size=16)\n",
    "\n",
    "# Predict probabilities for each category for new text inputs\n",
    "def predict_probabilities(text):\n",
    "    # Tokenize text\n",
    "    encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors='tf')\n",
    "    \n",
    "    # Predict probabilities\n",
    "    logits = model(encoded_input)[0]\n",
    "    probabilities = tf.nn.softmax(logits, axis=1)\n",
    "    \n",
    "    return probabilities.numpy()[0]\n",
    "\n",
    "# Example usage:\n",
    "new_text = \"I am passionate about coding and building software.\"\n",
    "probabilities = predict_probabilities(new_text)\n",
    "category_probabilities = {label: prob for label, prob in enumerate(probabilities)}\n",
    "print(category_probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0cf9196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.0007894639, 1: 0.00047684525, 2: 0.00078851514, 3: 0.007558828, 4: 0.00090521085, 5: 0.75302744, 6: 0.2364537}\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "new_text = \"Having worked in sales for over a decade, I have developed a keen understanding of market trends and customer behavior.\"\n",
    "probabilities = predict_probabilities(new_text)\n",
    "category_probabilities = {label: prob for label, prob in enumerate(probabilities)}\n",
    "print(category_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42524232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Having worked in sales for over a decade, I have developed a keen understanding of market trends and customer behavior.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Having worked in sales for over a decade, I have developed a keen understanding of market trends and customer behavior.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "31867e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Throughout my life, I've been fascinated by the intricate workings of the human body and the pursuit of understanding diseases and their treatments. From a young age, I've been drawn to biology and chemistry, eagerly devouring books and articles on topics ranging from genetics to pharmacology. My dream is to become a doctor and make a meaningful impact on the lives of others through the practice of medicine.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Throughout my life, I've been fascinated by the intricate workings of the human body and the pursuit of understanding diseases and their treatments. From a young age, I've been drawn to biology and chemistry, eagerly devouring books and articles on topics ranging from genetics to pharmacology. My dream is to become a doctor and make a meaningful impact on the lives of others through the practice of medicine.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15733e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.0002650557, 1: 0.10477058, 2: 0.88852096, 3: 0.0043039164, 4: 0.00050196185, 5: 0.00046636706, 6: 0.0011712192}\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "new_text = \"Throughout my life, I've been fascinated by the intricate workings of the human body and the pursuit of understanding diseases and their treatments. From a young age, I've been drawn to biology and chemistry, eagerly devouring books and articles on topics ranging from genetics to pharmacology. My dream is to become a doctor and make a meaningful impact on the lives of others through the practice of medicine.\"\n",
    "\n",
    "probabilities = predict_probabilities(new_text)\n",
    "category_probabilities = {label: prob for label, prob in enumerate(probabilities)}\n",
    "print(category_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d45515",
   "metadata": {},
   "source": [
    "Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d8877df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert_model were not used when initializing TFDistilBertForSequenceClassification: ['dropout_59']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert_model and are newly initialized: ['dropout_79']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "815/815 [==============================] - 2038s 2s/step - loss: 0.2851 - accuracy: 0.9041\n",
      "Epoch 2/3\n",
      "815/815 [==============================] - 17208s 21s/step - loss: 0.1728 - accuracy: 0.9401\n",
      "Epoch 3/3\n",
      "815/815 [==============================] - 4560s 6s/step - loss: 0.1430 - accuracy: 0.9535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x14f5385d2b0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save_pretrained(\"distilbert_model\")\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert_model\")\n",
    "\n",
    "# Optionally, you can continue fine-tuning the loaded model\n",
    "# Compile the loaded model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = ['accuracy']\n",
    "loaded_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "# Fine-tune the loaded model\n",
    "loaded_model.fit(train_dataset.shuffle(1000).batch(16), epochs=3, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b3a2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
